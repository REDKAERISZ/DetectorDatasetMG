{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for YOLONAS based detection models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains the code necessary for: \n",
    "* Rescaling the images to 1080 x 1080 pixels without distortion by completing the longest side with zeros\n",
    "* Computing the Region Of Interest coordinates for the new size\n",
    "* Generating a training dataset with labels and normalized coordinates in .txt format [label centerX centerY width height].\n",
    "\n",
    "The abnormality classes adressed in this experiment are: 1 Architectural distortion, 2 Mass and 3 Calcification\n",
    "\n",
    "The public datasets used are: \n",
    "\n",
    "* MIAS\n",
    "* CBIS-DDSM\n",
    "* CDD-CESM\n",
    "* INbreast\n",
    "* BMCD\n",
    "* VinDr\n",
    "\n",
    "To which I'll provide a link to their respective documentation within the README.md. I will also provide in this repository the .xlsx file containing the coordinates to every ROI. Take into consideration that the images from the MIAS database have been rotated, squared and transformed into DICOM so the coodinates here displayed will not fit the original PGM images. \n",
    "\n",
    "Don't forget to modify the image paths in the 'AbsPath' column according to your own storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "this_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates file \n",
    "\n",
    "This code computes the necessary data to obtain both COCO and YOLO format labels. Larger dataframes will take a long time to process. Progress can be tracked with the tdqm module.\n",
    "This cell has already been run, so you can save time by using the .csv as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '..\\\\DetectorDatasetMG\\\\Templatedetfile.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6678/6678 [56:53<00:00,  1.96it/s]  \n"
     ]
    }
   ],
   "source": [
    "class ImageNumbering:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prev_row = None\n",
    "        self.current_num = 1\n",
    "        self.current_idx = 1\n",
    "\n",
    "    def update_row(self, row):\n",
    "        row, self.prev_row, self.current_num, self.current_idx = utils.assign_image_numbers(row, self.prev_row, self.current_num, self.current_idx)\n",
    "        row = utils.assign_labels_and_names(row)\n",
    "        row = utils.resized_normalized_coordinates(row)\n",
    "        return row\n",
    "\n",
    "\n",
    "tqdm.pandas() # Initialize tqdm for progress bar\n",
    "img = ImageNumbering()\n",
    "df_progress = df.progress_apply(img.update_row, axis=1)\n",
    "\n",
    "df_progress.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to get a different dataset split [train, test, valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_dl_folder (csv_file, ratio):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    #Just to be sure...\n",
    "    assert len(ratio) == 3, \"Ratio must be a tuple of three elements\"\n",
    "    assert sum(ratio) <= 1, \"Sum of ratio must be less than or equal to 1\"\n",
    "    \n",
    "    categories = ['train', 'valid', 'test']\n",
    "    \n",
    "    df['set'] = np.random.choice(categories, size=len(df), p=ratio)\n",
    "    \n",
    "    df.to_csv(csv_file, index =False)\n",
    "\n",
    "assign_dl_folder(csv_file, ratio=(0.8, 0.15, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Excel file contains all the needed information to generate the dataset. Please review the comments on utils.py and processing.py for further information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing\n",
    "#### WARNING: This algorithm is not GPU accelerated yet and takes a long time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(row, root):\n",
    "    if row['AbsPath'].endswith(('.dcm', '.dicom', '.DCM')):\n",
    "        image = dicom_preprocessing(row['AbsPath'], row['pixy'], row['pixx'])\n",
    "    else:\n",
    "        image = cv2.imread(row['AbsPath'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = reduce_poisson_noise(image)\n",
    "    squared = add_zeros_for_square(image, row['pixy'], row['pixx'])\n",
    "    det_size = (1080, 1080)\n",
    "    resized_squared = cv2.resize(squared, det_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Build storing path\n",
    "    image_folder = os.path.join(root, row['set'], 'images')\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    image_name = f\"{row['ImageName']}.png\"\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    cv2.imwrite(image_path, resized_squared)\n",
    "\n",
    "    # Write label information to text file\n",
    "    label_folder = os.path.join(root, row['set'], 'labels')\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    label_file_path = os.path.join(label_folder, f\"{row['ImageName']}_{row['Index']}.txt\")\n",
    "    with open(label_file_path, 'w') as f:\n",
    "        f.write(f\"{row['Label']} {row['cx']} {row['cy']} {row['nw']} {row['nh']}\")\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"..\\\\DetectorDatasetMG\\\\data\" \n",
    "df = pd.read_csv(csv_file)\n",
    "tqdm.pandas() \n",
    "df_process_progress = df.progress_apply(lambda row: data_processing(row, root), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__\n",
    "import shutil\n",
    "\n",
    "def copy_images_with_names(df, source_column, name_column, destination_folder):\n",
    "    # Ensure the destination folder exists\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    # Iterate over the DataFrame rows and copy each image\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Copying images\"):\n",
    "        source_path = row[source_column]\n",
    "        image_name = row[name_column]\n",
    "        destination_path = os.path.join(destination_folder, image_name)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "\n",
    "        \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "destination_folder = '../DetectorDatasetMG/data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████| 269/269 [00:34<00:00,  7.74it/s] \n"
     ]
    }
   ],
   "source": [
    "copy_images_with_names(df, 'AbsPath', 'ImageName', destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1% reached at 5 minutes "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
